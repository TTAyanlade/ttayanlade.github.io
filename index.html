<!DOCTYPE HTML>
<html lang="en">
  <head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-7467KWZ9K9"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-7467KWZ9K9');
    </script>
      
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">


  <title>Timilehin Ayanlade</title>
  
  <script>
    function toggleDropdown() {
        const container = document.querySelector('.dropdown-container');
        container.classList.toggle('active');
    }
  </script>
  
  <style>
    /* Base styles for the container */
    .dropdown-container {
        position: relative;
        width: 100%;
        max-width: 600px; /* or any desired max-width */
        margin: 20px auto;
    }

    /* The hidden content */
    .dropdown-content {
        display: none;
        width: 100%;
        border-top: 1px solid #aaa;
    }

    /* The button with a downward arrow */
    .dropdown-button {
        display: inline-block;
        background-color: transparent;
        border: none;
        font-size: 24px;
        cursor: pointer;
        position: absolute;
        bottom: 0;
        left: 50%;
        transform: translateX(-50%);
    }

    /* Display content when container is active */
    .dropdown-container.active .dropdown-content {
        display: block;
    }
  </style>
  <meta name="google-site-verification" content="nzy2wGreBPRHJF7qNoQFCBTZgvuhpnnO8zR822ra3fU" />
  <meta name="my_name" content="Timilehin Ayanlade">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Timilehin Ayanlade</name>
              </p>

              <p style="text-align:center">
                <a href="mailto:ayanlade@iastate.edu">Email</a> &nbsp|&nbsp
                <a href="data/timilehin_ayanlade_cv.pdf">CV</a> &nbsp|&nbsp
                <a href="https://scholar.google.com/citations?user=SI6VhjMAAAAJ&hl=en">Google Scholar</a> &nbsp|&nbsp
                <a href="https://github.com/ttayanlade">GitHub</a>&nbsp|&nbsp
                <a href="https://www.linkedin.com/in/timilehin-ayanlade/">LinkedIn</a>&nbsp
              </p>

              <p>I am a PhD student at the <a href="https://sites.google.com/view/scslab-isu//">Self Aware Complex Systems Laboratory</a> at the <a href="https://trac-ai.iastate.edu/">Translational AI Center</a> in <a href="https://www.iastate.edu/">Iowa State University</a>, where I work with <a href="https://scholar.google.com/citations?user=-rmRjqIAAAAJ&hl=en">Professor Soumik Sarkar</a>.
              </p>
              <p>Working on Machine Learning for Multimodal Understanding in Cyber-Agricultural Systems.</p>

              
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/JonBarron.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/timilehin.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research focus centers on advancing cutting-edge machine learning techniques for Multimodal Cyberagricultural Systems. I specifically concentrate on addressing challenges related to the deployment and application of machine learning models in agricultural settings for high-throughput pipelines. In addition to this, I investigate the robustness, explainability, and trustworthiness of deployed models.

              </p>
            </td>
          </tr>
        </tbody></table>
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/quilt1m.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2306.11207">
                <papertitle>Quilt-1M: One Million Image-Text Pairs for Histopathology.</papertitle>
              </a>
              <br>
              <strong>Timilehin Ayanlade</strong>, <a href="https://arxiv.org/search/cs?searchtype=author&query=Seyfioglu%2C+M+S">
                 Mehmet Saygin Seyfioglu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&query=Shapiro%2C+L">
                Fatemeh Ghezloo, Dylan Geva, Fatwir S. Mohammed, Pavan K. Anand, Ranjay Krishna and Linda Shapiro</a>
              <br>
              <em>NeurIPS (ORAL)</em> June 2023.
                <details>
                  <summary>Recent accelerations in multi-modal applications have been made possible with the plethora of image and text data available online. However, the scarcity of similar data in the medical field, specifically in histopathology, has slowed similar progress. To enable similar representation learning 
                    for histopathology, we turn to YouTube, an untapped resource of videos, offering 1,087 hours of valuable educational histopathology videos from expert clinicians. From YouTube, we curate Quilt: a large-scale vision-language dataset consisting of 802,148 image and text pairs.
                  </summary>
                  <p>
                    Quilt was automatically
                     curated using a mixture of models, including large language models, handcrafted algorithms, human knowledge databases, and automatic speech recognition. In comparison, the most comprehensive datasets curated for histopathology amass only around 200K samples. We combine Quilt with datasets, 
                     from other sources, including Twitter, research papers, and the internet in general, to create an even larger dataset: Quilt-1M, with 1M paired image-text samples, marking it as the largest vision-language histopathology dataset to date. We demonstrate the value of Quilt-1M by fine-tuning a 
                     pre-trained CLIP model. Our model outperforms state-of-the-art models on both zero-shot and linear probing tasks for classifying new pathology images across 13 diverse patch-level datasets of 8 different sub-pathologies and cross-modal retrieval tasks.
                    
                  </p>
                </details>

            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/multiscale_.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/pdf/2209.01534">
                <papertitle>Multi-Scale Cross-Attention Multiple Instance Learning Network for
                  Risk Stratification of Whole Slide Images.</papertitle>
              </a>
              <br>
              <strong>Timilehin Ayanlade</strong>, <a href="https://arxiv.org/search/cs?searchtype=author&query=Seyfioglu%2C+M+S">
                Christopher Chandler, Jatin S. Gandhi, Annie Garcia, Courtney Daum,
                Elizabeth Loggers, Linda G. Shapiro, Jose G. Mantilla, Anshu Bandhlish, Robert W. Ricciotti</a>
              <br>
              <em>Abstract (Oral Platform Presentation)*, United States and Canadian Academy of Pathology (USCAP)</em> April 2023.
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/mmae2.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/pdf/2209.01534">
                <papertitle>Multi-modal Masked Autoencoders Learn Compositional Histopathological Representations.</papertitle>
              </a>
              <br>
              <strong>W.O. Ikezogwo</strong>, <a href="https://arxiv.org/search/cs?searchtype=author&query=Seyfioglu%2C+M+S"> Mehmet Saygin Seyfioglu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&query=Shapiro%2C+L">Linda Shapiro</a>
              <br>
              <em>Extended abstract: Machine Learning for Health (ML4H),</em> Dec 2022.
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cbm2020.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S0010482520301323">
                <papertitle>Supervised domain generalization for integration of disparate scalp EEG datasets for automatic epileptic seizure detection</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=aYIMS9gAAAAJ&hl=en">K.P. Ayodele</a>, <strong>W.O. Ikezogwo</strong>, <a href="https://www.mendeley.com/authors/11939648100/">M.A. Komolafe</a>, <a href="https://scholar.google.com/citations?user=hInUS0QAAAAJ&hl=en"> P. Ogunbona</a>
              <br>
              <em>Computers in Biology and Medicine</em> Volume 120, May 2020, 103757
              <p>We use supervised domain generalization to combine disparate EEG datasets and a recurrent convolutional neural network detector to test the generalizability of the trained model on an out-of-distribution private epilepsy seizure dataset.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ijoe.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://pdfs.semanticscholar.org/76bf/7ea4c1c7817cfae5c356cd4fd17f397336fe.pdf">
                <papertitle>Empirical Characterization of the Temporal Dynamics of EEG Spectral Components.</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=aYIMS9gAAAAJ&hl=en">K.P. Ayodele</a>, <strong>W.O. Ikezogwo</strong>, Anthony A. Osuntunyi
              <br>
              <em>International Journal of Online and Biomedical Engineering (iJOE)</em>  Volume 16, Dec 2020.
            </td>
          </tr>

        </tbody></table> -->
    
        









    <!-- <section id="news-updates">
      <h2>News & Updates</h2>

       <article class="update">
        <h3> Medical AI Renaissance Proposal Accepted for Microsoft's Accelerating Foundation Model Research Grant. <span class="date">October, 2023</span></h3>
        <p><a href="https://www.microsoft.com/en-us/research/collaboration/accelerating-foundation-models-research/phase-ii/#:~:text=Medical%20AI%20Renaissance%3A%20A%20Trio%20of%20Medical%20Projects%20from%20Data%20Curation%20to%20Multi%2DModal%20Chatbot%20Training%20to%20Evaluation%0AUniversity%20Of%20Washington%2C%20Linda%20Shapiro" target="_blank">Read here</a>.</p>
      </article>

  </section> -->
  







  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr>
        <td>
          <heading>Service</heading>
        </td>
      </tr>
    </tbody>
  </table>
  
  <table width="100%" align="center" border="0" cellpadding="20">
    <tbody>
      <tr>
        <td width="100%" valign="center">
          <ul>
            <li>Reviewer for WiCV, <a href="https://iccv2023.thecvf.com/list.of.accepted.workshops-90.php">ICCV</a></li>
            <li>Co-managed the Fourth Machine Learning for CyberAgricultural Systems Workshop. <a href="https://mlcas2022.github.io/">MLCAS</a></li>
          </ul>
        </td>
      </tr>
    </tbody>
  </table>
  



  
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr>
        <td>
          <heading>News Feature</heading>
        </td>
      </tr>
    </tbody>
  </table>
  
  <table width="100%" align="center" border="0" cellpadding="20">
    <tbody>
      <tr>
        <td width="100%" valign="center">
          <ul>
            <li><a href="https://guardian.ng/features/shaping-the-future-of-agriculture-timilehin-ayanlade-leads-artificial-intelligence-efforts-in-agriculture/">Shaping the Future of Agriculture: Timilehin Ayanlade leads artificial intelligence efforts in agriculture.</a><br>
               The Guardian, February 11, 2023</li>
            <li><a href="https://www.vanguardngr.com/2022/10/agri-tech-expert-timilehin-ayanlade-advocates-for-sustainable-innovation-in-agricultural-sector/">Agri-tech expert, Timilehin Ayanlade advocates for sustainable innovation in Agricultural sector.</a> <br> 
              Vanguard NGR, October 6, 2022</li>
          </ul>
        </td>
      </tr>
    </tbody>
  </table>




        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Others</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/runmila.png" alt="runmila" width="160" height="160">
            </td>
            <td width="75%" valign="center">
              <p> <strong>School</strong> : <a href="https://www.linkedin.com/company/runmila-ai-institute/"> Runmila AI Institute Ghana | 2021 |</a> </p>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/aicommons.svg" alt="aicommons" width="160" height="160">
            </td>
            <td width="75%" valign="center">
              <p> <strong>School</strong> : <a href="https://ai-commons.org/"> AI Commons Canada | 2021 |</a> </p>
              <br>
            </td>
          </tr>

        </tbody></table> 








        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <br>
                <a href="https://people.eecs.berkeley.edu/~barron/">Website credits: Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
